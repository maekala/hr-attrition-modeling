{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69c84753-1335-4230-b012-adc620e2f4cd",
   "metadata": {},
   "source": [
    "## SHAP Explainability for XGBoost Model\n",
    "\n",
    "To make our attrition model more interpretable and actionable for HR professionals, we use SHAP (SHapley Additive exPlanations). SHAP brings visual and quantitative insights into how each feature impacts individual predictions, allowing HR teams to understand *why* the model predicts that an employee might leave. By examining these explanations, HR can design more targeted interventions. For example, addressing frequent overtime, improving job satisfaction, or adjusting policies that disproportionately affect certain employee groups.\n",
    "\n",
    "We'll generate:\n",
    "- A summary plot showing the most influential features across the dataset.\n",
    "- An individual force plot showing how features contribute to a single employee's attrition risk.\n",
    "\n",
    "These visualizations will be saved in the `visuals/` folder for easy access and potential integration into a Tableau dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fcd35a9-c8f6-44e8-a5ac-9ba25676be58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load processed data\n",
    "df = pd.read_csv(\"../data/processed_attrition.csv\")\n",
    "X = df.drop(columns=[\"Attrition\"])\n",
    "y = df[\"Attrition\"]\n",
    "\n",
    "# Re-train model (or use your tuned model if already saved)\n",
    "xgb_model = XGBClassifier(learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8, eval_metric='logloss')\n",
    "xgb_model.fit(X, y)\n",
    "\n",
    "# Create SHAP explainer\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "# Save SHAP summary plot\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values, X, plot_type=\"bar\", show=False)\n",
    "plt.xlabel(\"Mean Absolute SHAP Value (Impact on Attrition Prediction)\", fontsize=12)\n",
    "plt.ylabel(\"Feature\", fontsize=12)\n",
    "plt.title(\"Top Features Contributing to Employee Attrition\", fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../visuals/shap_summary_plot.png\")\n",
    "plt.close()\n",
    "\n",
    "# Save individual force plot (e.g., employee index 0)\n",
    "# Force plot for a single employee with labeled axes\n",
    "plt.figure()\n",
    "shap.plots._waterfall.waterfall_legacy(explainer.expected_value, shap_values[0], X.iloc[0], show=False)\n",
    "plt.suptitle(\"Employee Attrition Risk Breakdown (Example: Index 0)\", fontsize=14, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../visuals/shap_force_plot_example.png\", bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72436c1b-5849-4b38-b43f-3808c51d395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the indices of the additional employees you'd like to analyze\n",
    "example_indices = [5, 12]\n",
    "\n",
    "# Loop through and generate force/waterfall plots\n",
    "for i in example_indices:\n",
    "    plt.figure()\n",
    "    shap.plots._waterfall.waterfall_legacy(\n",
    "        explainer.expected_value, shap_values[i], X.iloc[i], show=False\n",
    "    )\n",
    "    plt.suptitle(f\"Employee Attrition Risk Breakdown (Example: Index {i})\", fontsize=14, y=1.05)\n",
    "    \n",
    "    # Save plot to visuals folder\n",
    "    filename = f\"../visuals/shap_force_plot_example_{i}.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd275f7-b946-43b8-8d28-28e79cef6e56",
   "metadata": {},
   "source": [
    "## SHAP Explainability: What Drives Attrition?\n",
    "\n",
    "SHAP was used to interpret both overall and individual-level predictions from our XGBoost attrition model.\n",
    "\n",
    "### Global Insights: Top Predictive Features\n",
    "The summary plot shows that:\n",
    "- **OverTime**, **StockOptionLevel**, and **MonthlyIncome** are the most important features driving attrition predictions.\n",
    "- Features tied to **satisfaction**, **career progression**, and **commute** also have strong effects.\n",
    "- These insights align with common drivers of employee disengagement and offer clear focus areas for HR intervention.\n",
    "\n",
    "### Individual Prediction Example\n",
    "We analyzed one specific employee (Index 0) in detail using a SHAP force plot:\n",
    "- The model predicted high attrition risk due to **heavy overtime**, **poor work-life balance**, and **limited recent training**.\n",
    "- Some factors, like **job satisfaction** and **relationship satisfaction**, helped reduce that risk, but not enough.\n",
    "- This kind of breakdown is ideal for real-world application â€” helping HR not only detect risk, but **understand the reasons** and develop personalized retention strategies.\n",
    "\n",
    "SHAP visualizations make the model transparent, trustworthy, and actionable for non-technical stakeholders."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
